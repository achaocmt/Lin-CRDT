%!TEX root = draft.tex
\section{Proving \CRDTLin{}}
\label{sec:proofs}

We describe a proof methodology for showing that CRDT objects are \crdtlinearizable{}. 
This methodology consists of an inductive invariant proof combined with a simulation proof based on  
refinement mappings~\cite{DBLP:journals/tcs/AbadiL91,DBLP:journals/iandc/LynchV95}, 
to show that the evolution of replica states can be simulated by the specification.

\subsection{Proof Methodology}\label{ssec:proof-methodology}

In order to show \crdtlin{} (w.r.t. a specification $\Spec{}$) we start by
instrumenting the object semantics with an auxiliary variable
$\alinord$ recording a linearization of the current history (i.e., the history recorded
in the object's global configurations). 
%This follows a rather standard approach for 
%proving classical linearizability, 
%of~\cite{AbadiL91, VafeiadisHHS06, more citations}.

As explained in Section~\ref{sec:overview} there are two actions in the
semantics that can modify the state of replicas:
\begin{inparaenum}
\item the execution of a new client request at the source replica,
  which is shown under the \lstinline|atSource| label -- immediately
  followed by the \lstinline|downStream| at the source replica
  --, or
\item the execution of the effector of an operation originating in a
  different replica shown under the \lstinline|downStream| label of
  the implementation.
\end{inparaenum}
%
While the execution of an operation at its source replica represents
the arrival of a new operation, the execution of 
\lstinline|downStream| in a different replica represents the
propagation of effects of preexisting operations.
%
Since the sequence $\alinord$ is a global order over all the
operations of the object in the system, it needs only be updated when
a \emph{new} operation arrives, therefore only during the execution of the code under the
\lstinline|atSource| label\footnote{For readers familiars with proving classical
  linearizability for concurrent objects, this is akin to assuming that
  \lstinline|atSource| is a ``fixed'' linearization point.
  However, differently from the classical case, the operation may not
  be necessarily placed at the end of the current linearization.},
by adding the current operation at some specific position.
%
%In this paper we only consider CRDTs whose linearizations are
%consistent with the visibility of operations.
%%
%That is, the order of linearization of an execution respects the
%causality of in the execution.\footnote{In fact, we are not aware of
%  \CRDTLinshort{} CRDTs where this is not true.}
%
To guarantee that the linearization is consistent with the visibility
relation, the operation must be inserted in the linearization after
all the operations which are visible at the replica executing
\lstinline|atSource| (we will give later two different strategies for achieving this requirement).
%%
%\gpnote*{Clarify?}
%{
%This guarantees that the linearization $\alinord$ is consistent with
%the visibility relation.
%}
When the object contains query-update operations, the operations are
first rewritten according to a query-update rewriting $\gamma$ as in
\autoref{definition:distributed linearizability} before being placed
in the linearization.
Then, the objective is to prove that whether $\alinord$ is an
\crdtlinearization{} of the current history (w.r.t. $\Spec{}$) is an
invariant for any execution of the object.
%
To prove this invariant, we strengthen it with additional requirements
in order to make it inductive.
%
In the case of the objects we investigated, the inductive invariant is
defined as the conjunction of two properties:
\begin{itemize}
%\setlength{\itemsep}{0.5pt}
\item[-] $\mathsf{ReplicaStates}$: requiring that for each replica
  $\arep$ with local configuration $(\alabelset,\astate)$, the state
  $\sigma$ is obtained by applying the effectors of the operations
  in $\alabelset$ (that have been delivered to $\arep$) \emph{in the order
  defined by $\alinord$}, and
\item[-] $\mathsf{\CRDTLinshort{}}$: requiring that the sequence
  $\alinord$ is an \crdtlinearization{} of the current history (w.r.t.
  $\Spec{}$).
% is \crdtlinearizable{} w.r.t \Spec{} and $\mathit{lin}$ is a
% linearization. Here $\alabelset$ is the set of labels in domain of
% $\downstreams$.
\end{itemize}
To prove that this is an inductive invariant we rely on additional
assertions describing the effect of each downstream (we provide
examples in the following subsections), joint with a proof that:
\begin{itemize}
%\setlength{\itemsep}{0.5pt}
\item[-] $\mathsf{Refinement}$: each effector produced by an operation
  $\alabel$, respectively each query $\alabel$, is simulated by the
  execution of $\alabel$ in the specification $\Spec$. 
\end{itemize}
Essentially, this last requirements establishes a strong
correspondence between the implementation of the algorithm and its
specification. Actually, when using query-updates rewritings $\gamma$, $\mathsf{Refinement}$ requires that 
the effector produced by an operation $\alabel$ be simulated by $\secondrep(\gamma(\alabel))$ 
(the update label in the image of $\alabel$ w.r.t. $\gamma$) in the specification. 

The proof of $\mathsf{Refinement}$ relies on a \emph{refinement
  mapping}~\cite{AbadiL91,DBLP:journals/iandc/LynchV95} between replica states and states of the
specification, denoted by $\refmap$. Intuitively, $\refmap$ being a refinement mapping means that any
effector or query applied on a replica state $\sigma$ can be mimicked by the corresponding operation in the specification
starting from $\refmap(\sigma)$ and leading to a specification state which is related by $\refmap$ to the resulting
replica state.
More precisely, it is required that for 
any two replica states $\sigma$ and $\sigma'$,
\begin{enumerate}
        \item if $\sigma'$ is obtained from $\sigma$ by applying an
          effector $\delta$ produced by an operation $\alabel$, then
          \mbox{$\refmap(\sigma)\xrightharpoonup{\alabel}\refmap(\sigma')$},
          where $\xrightharpoonup{\alabel}$ is the transition function of
          $\Spec$, or \mbox{$\refmap(\sigma)\xrightharpoonup{\secondrep(\gamma(\alabel))}\refmap(\sigma')$} 
          when a query-update rewriting $\gamma$ is used,
          and
          \gpwarning{The match between labels and $\delta$ has to be made more explicit somewhere}
        \item if a query $\alabel$ is applied on a state $\sigma$ or
          it is introduced by a rewriting of a query-update that
          executes \lstinline|atSource| on a state $\sigma$, then
          $\refmap(\sigma)\xRightarrow{\alabel}\refmap(\sigma)$.
\end{enumerate}
% \gpnote*{Explain or remove}{
% Actually, for the CRDT objects presented in Section~\ref{subsec:time order of execution as linearization}, we consider a stronger version of $\mathsf{Refinement}$ which requires that the state $\sigma$ and the downstream $\delta$ satisfy some particular condition (in the context of the first proof goal).
% }

\gpnote[nomargin, inline]{Forward reference to exec-order, and
  ts-order.}
We have applied this methodology to a range of CRDT objects described
in~\cite{ShapiroPBZ11}, and we have identified two general classes of
CRDT implementations which differ in the way in which the
linearization $\alinord$ is extended when executing the operations at
the source replica.
For the first class of objects, which includes the OR-Set in
Listing~\ref{lst:or-set}, the linearization $\alinord$ is defined by
the order in which the operation is executed at their source (that is
when the pair of labels \lstinline|atSource| and
\lstinline|downstream| are executed for the first time in the source
repolica).
In this case the new operation is immediately appended
to the current linearization $\alinord$ (\S~\ref{subsec:time order of execution
  as linearization}).
We say that such objects admit \emph{execution-order linearizations}.
The second class of objects, including the RGA CRDTlin in
Listing~\ref{lst:rga}, supports \CRDTLinshort{} proofs in which the
linearization is built based on timestamps, e.g., $\alinord$ is
consistent with the order between the timestamps generated by
operations (\S~\ref{subsec:time-stamp order as linearizabtion}).
We say that such objects admit \emph{timestamp-order linearizations}.

We will now illustrate these proof strategies through the RGA and
OR-Set examples.
%
We will in each case leave a semi-formal argument for their
linearizability, and explain the commonalities of all other CRDTs in
the same class.
%
The formal proofs are relegated to~\autoref{sec:appendix proofs of
  crdt implementations}.

%
%For some CRDT implementations, when proving its correctness, we can use the total-order of executions as linearization. For such CRDT implementations, our proof approach is as follows:
%
%
%Given a object $\aobj$ and a specification \Spec{}, we construct a predicate $P(\mathit{config},\mathit{lin})$ where $\mathit{config} = (\gstates, \avisord, \downstreams)$ is a configuration of $\llbracket \aobj \rrbracket_{\mathit{op}}$, and $\mathit{lin}$ is a sequence used as linearization. We require $P(\mathit{config},\mathit{lin})$ to be a conjunction of the following statements:
%
%\begin{itemize}
%\setlength{\itemsep}{0.5pt}
%\item[-] Condition $C_1$ (linearizability): The history $(\alabelset, \avisord)$ is \crdtlinearizable{} w.r.t \Spec{} and $\mathit{lin}$ is a linearization. Here $\alabelset$ is the set of labels in domain of $\downstreams$.
%
%\item[-] Condition $C_2$ (downstream): A statement about downstream for each operation label in $\mathit{config}$.
%
%\item[-] Condition $C_3$ (sequential explanation): For each replica $\arep$, we have that $\gstates(\arep).\astate = \mathit{apply}(\mathit{lin},\gstates(\arep).\alabelset)$.
%\end{itemize}
%
%Here the function $\mathit{apply}(\mathit{lin},S)$ returns a local state obtained by applying downstream of operations in $S$ according to total order of $\mathit{lin}$.

\subsection{Execution-Order Linearizations}
\label{subsec:time order of execution as linearization}

%Then, we need to prove that $P$ is a simulation relation. Moreover, we prove that we can always obtain a new linearization by putting a new operation after the tail of a old linearization. We call such relation a execution-order simulation relation.
%
%\begin{itemize}
%\setlength{\itemsep}{0.5pt}
%\item[-] $P(\mathit{config}_0,\epsilon)$ holds, where $\mathit{config}_0$ is the initial configuration.
%
%\item[-] If $P(\mathit{config},\mathit{lin})$ holds and $\mathit{config} {\xrightarrow{\alabel}} \mathit{config}'$, then $P(\mathit{config}', \mathit{lin} \cdot \alabel)$ holds.
%
%\item[-] If $P(\mathit{config},\mathit{lin})$ holds and $\mathit{config} {\xrightarrow{}} \mathit{config}'$, then $P(\mathit{config}',\mathit{lin})$ holds.
%\end{itemize}
%
%It is easy to see that, execution-order simulation relation implies a \crdtlinearizable{} relation proof with the execution as linearization.

In this section, we describe a first instantiation of the methodology described above using as example the OR-Set object in Listing~\ref{lst:or-set}. The proof that this object satisfies \crdtlin{} w.r.t. the specification defined in Example~\ref{} relies on several annotations which are given on the lines starting with {\tt //@} in Listing~\ref{lst:or-set} and that we describe hereafter.

%a two-vocabulary formula, the primed, resp., unprimed, variables denoting values after, resp., before, the execution of the procedure.

The annotations included in the \lstinline|atSource| labels describe the construction of the linearization,
%We describe updates of the linearization using \lstinline|let| constructs that append a set of labels.
which is extended by appending operations to the abstract $\alinord$ linearization, after possibly rewriting them through the query-update rewriting $\gamma$ defined in Example~\ref{}. %, when they execute the \lstinline|atSource| procedure.
The annotations of the downstreams specify their effect, e.g., relating their effect with the set of operations visible to the replica where this operation has originated (when the downstream has been computed). These annotations are written as two-vocabulary formulas, the primed, resp. unprimed, variables denoting values of variables after, resp. before, the execution of the downstream.
For instance, the downstream corresponding to a {\tt remove} operation removes the set of element-id pairs added by {\tt add} operations visible at the replica $\arep$ where the {\tt remove} originated, and which were not ``canceled'' by other {\tt remove}s visible at $\arep$ ({\tt remove}s that saw those {\tt add} operations).

\gp{red = we have to talk about it before?}
In the following, we show that the $\mathsf{ReplicaStates}$ property described above is an inductive invariant for OR-Set. Since every operation is appended to the linearization when it executes \lstinline|atSource| it clearly follows, in the linearization order, all operations visible to it. Then, by the {\textred{causal delivery}} assumption, the order in which downstreams are applied at a given replica is also consistent with the visibility order. 
The main difficulty in showing that $\mathsf{ReplicaStates}$ is an inductive invariant occurs in the case when two downstreams corresponding to two concurrent operations (that is, not related by visibility) have to be linearized in an order which does not coincide with the order in which their downstreams might have been applied in one or more of the replicas. It is important to recall at this point that concurrent operations can be applied in different orders in different replicas. 
% The main difficulty in showing that $\mathsf{ReplicaStates}$ is an inductive invariant is when two downstreams correspond to two ``concurrent'' operations (not related by visibility) and their linearization order is different from the order in which they are applied at a given replica.
% \gpnote*{Refine this text.}
Importantly, a fundamental property of CRDTs~\cite{ShapiroPBZ11} is that the downstreams of concurrent operations should \emph{commute}. In other words, applying them in any order leads to the same state.
The fact that concurrent downstreams commute is an easy consequence of the downstream annotations: two {\tt add} or two {\tt remove} downstreams commute obviously because they both add or both remove element-id pairs, while an {\tt add} and a {\tt remove} downstream commute when they are concurrent because in this case, the element-id pairs removed by {\tt remove} are different from the pair added by the {\tt add} (since the {\tt add} is not visible to {\tt remove}).

The proof of $\mathsf{Refinement}$ is quite straightforward. We consider a refinement mapping $\refmap$ defined as the identity function. For instance, applying the downstream produced by $\alabelshort[{\tt add}]{a,k}$~\footnote{In the proof of $\mathsf{Refinement}$, we implicitly assume that whenever an operation label $\alabel$ is rewritten to another label $\alabel'$, e.g. $\alabelshort[{\tt add}]{a}$ is rewritten to $\alabelshort[{\tt add}]{a,k}$, then the downstream produced by the original operation $\alabel$ must be simulated by the operation $\alabel'$ in the specification. Similarly, for query-updates $\alabel$ rewritten to $(\alabel_1,\alabel_2)$, the downstream produced by $\alabel$ must be simulated by the operation $\alabel_2$ in the specification. This is true in all of our proofs.} and the $\alabelshort[{\tt add}]{a,k}$ operation of the specification ??? has exactly the same effect. The same holds for the downstream produced by $\alabelshort[{\tt remove}]{a,R}$. Concerning query operations, there are two cases: (1) whenever the query-update $\alabelshort[{\tt remove}]{a}$ executes \lstinline|atSource| on a state $\sigma$, then the query $\alabellong[{\tt readIds}]{a}{R}{}$ (introduced by the query-update rewriting) 
\gpnote*{?}{should be enabled in state $\refmap(\sigma)=\sigma$}, which clearly holds because the computation of $R$ in \lstinline|atSource| and as the result of $\alabelshort[{\tt readIds}]{a}$ in the specification state $\sigma$ are exactly the same, and (2) applying the query $\alabellongind[{\tt read}]{}{A}{}$ on the replica state $\sigma$ should result in the same return value as applying the same query in the context of the specification on the same state $\sigma$, which again holds trivially.

Finally, we describe the proof of the fact that $\mathsf{\CRDTLinshort{}}$ is an inductive invariant. As already mentioned, appending operations to the linearization when they execute \lstinline|atSource| clearly implies that $\alinord$ is consistent with visibility. Next, the projection of $\alinord$ on the updates is obviously admitted by the specification (the updates are always enabled from the point of view of the specification).
%The only thing to show is that the element-id pairs removed by a {\tt remove} have been added by {\tt adds} which precede it in the linearization, and not already removed by other {\tt remove}s that precede it. This is a direct consequence of the fact that the linearization order is consistent with the visibility relation, and the invariant $\mathsf{ReplicaStates}$, which implies that every element-id pair in a the state of a replica $\arep$ has been added by an {\tt add} visible to $\arep$ and not removed by other {\tt remove}s visible to $\arep$. Then,
\gpnote*{Not sure I understand the sentence}
{
We also have to argue that for each query $\alabel_{\mathsf{qr}}\in\{\alabellongind[{\tt readIds}]{a}{R}{},\alabellongind[{\tt read}]{}{A}{}\}$, the sequence $\alinord'\cdot \alabel_{\mathsf{qr}}$ where $\alinord'$ is the projection of $\alinord$ on the set of updates
visible to $\alabel_{\mathsf{qr}}$ is admitted by the specification.} First, by $\mathsf{ReplicaStates}$, the state $\sigma$ of the replica where $\alabel_{\mathsf{qr}}$ is applied is obtained by applying the downstreams of the operations visible to $\alabel_{\mathsf{qr}}$ in the linearization order. Then, by $\mathsf{Refinement}$, every downstream is simulated by the corresponding operation in the context of the specification. This implies that $\refmap(\sigma_0)\xRightarrow{\alinord'}\refmap(\sigma)$, where $\sigma_0$ is the initial replica state. The query $\alabel_{\mathsf{qr}}$ is also simulated by the same operation in the context of the specification, which implies that $\refmap(\sigma)\xRightarrow{\alabel_{\mathsf{qr}}}\refmap(\sigma)$. These two facts imply that $\refmap(\sigma_0)\xRightarrow{\alinord'\cdot \alabel_{\mathsf{qr}}}\refmap(\sigma)$ which means that $\alinord'\cdot \alabel_{\mathsf{qr}}$ is admitted by the specification.

TODO STATE WHICH OTHER OBJECTS SUPPORT THE SAME KIND OF PROOF.

\subsection{Timestamp-Order Linearizations}
\label{subsec:time-stamp order as linearizabtion}

CRDT objects such as RGA, that use timestamps for conflict resolution, may not admit execution-order linearizations. \fxwarning[nomargin, inline]{Example showing why execution-order linearizations are not valid for RGA.}
To prove that they are \crdtlinearizable{}, we consider an instantiation of the proof methodology described in Section~\ref{ssec:proof-methodology} where the linearization is additionally \emph{consistent with the order of timestamps} generated by the operations.
We describe this instantiation using the RGA object in Listing~\ref{lst:rga} as an example.

\gpnote{I think this example is kinda complicated. Maybe add picture?}
The construction of the linearization ensures that the operations that generate a timestamp, i.e., the invocations of ${\tt addAfter}$, are ordered in the linearization according to their timestamps. More precisely, for any two operations $\alabelshort[{\tt addAfter}]{a,b}$ and $\alabelshort[{\tt addAfter}]{c,d}$ that generate two timestamps $\ats_{\tt b}$ and $\ats_{\tt d}$, respectively, the linearization should order $\alabelshort[{\tt addAfter}]{a,b}$ before $\alabelshort[{\tt addAfter}]{c,d}$ if $\ats_{\tt b}<\ats_{\tt d}$ and $\alabelshort[{\tt addAfter}]{c,d}$ before $\alabelshort[{\tt addAfter}]{a,b}$ if $\ats_{\tt d}<\ats_{\tt b}$. 
%
Moreover, to extend the notion of timestamp ordering to operations $\alabel$ that don't generate timestamps, i.e., invocations of ${\tt remove}$ and ${\tt read}$, we consider a ``virtual'' timestamp which is defined as the \emph{maximal} timestamp of any operation visible to $\alabel$ (or $\bot$ if no operation is visible to $\alabel$), and then require that the linearization is consistent with the order between both ``real''~\footnote{That is, timestamps generated by the operation itself.} and ''virtual'' timestamps. \fxwarning[nomargin, inline]{Example showing a history and how the linearization evolves}

The annotations defining the linearization are included under the \lstinline|atSource| labels of~\autoref{lst:rga}. The function {\tt insert}($\alinord$,$\alabel$,$\ats$) inserts the label $\alabel$ in the linearization $\alinord$ just after the last operation $\alabel'$ in $\alinord$ which has a timestamp (real or virtual) smaller than or equal to $\ats$. The annotations describing the effect of downstreams are quite straightforward in this case, since they are logical interpretations of the program statements.

The proof of $\mathsf{ReplicaStates}$ is quite similar to the case of OR-Set. Since the order between the timestamps generated by ${\tt addAfter}$ operations is consistent with the visibility relation (see Section~\ref{ssec:semantics}), it easily follows that the linearization order $\alinord$ is also consistent with the visibility relation. Then, as in the case of OR-Set, it remains to prove that any two downstreams that correspond to two ``concurrent'' operations (not related by visibility) commute. This easily follows from the fact that the downstreams apply set union which is obviously commutative. Also, note that by the {\textred{causal delivery}} assumption and the preconditions of ${\tt addAfter}$ and ${\tt remove}$, it cannot happen that an $\alabelshort[{\tt addAfter}]{a,b}$ operation adding ${\tt b}$ after ${\tt a}$ is concurrent with an operation that adds ${\tt a}$ to the list, i.e., $\alabelshort[{\tt addAfter}]{c,a}$, for some ${\tt c}$, or that an $\alabelshort[{\tt addAfter}]{a,b}$ operation adding ${\tt b}$ is concurrent with an operation $\alabelshort[{\tt remove}]{b}$ that removes ${\tt b}$. This ensures that reordering concurrent downstreams doesn't lead to ``invalid'' replica states where for instance, the timestamp tree ${\tt N}$ contains nodes which are not reachable from the root (which would happen if $\alabelshort[{\tt addAfter}]{a,b}$ is delivered before the operation $\alabelshort[{\tt addAfter}]{c,a}$ adding ${\tt a}$), or where the tombstone set ${\tt Tomb}$ contains elements which are not in the tree (which would happen if $\alabelshort[{\tt remove}]{b}$ is delivered before $\alabelshort[{\tt addAfter}]{a,b}$).

{\color {red} CW: Each abstract state is in the form $\abstate = (a_1,flag_1) \cdot \ldots \cdot (a_n,flag_n)$.} Concerning the proof of $\mathsf{Refinement}$, we consider a refinement mapping $\refmap$ which relates a replica state with the sequence of elements given by the function ${\tt traverse}$ used in ${\tt read}$ operations, i.e., $\refmap(({\tt N},{\tt Tomb}))={\tt traverse(N, Tomb)}$. The fact that downstreams of ${\tt remove}$ operations, and ${\tt read}$ queries are simulated by the corresponding operations of the specification (defined in ???) is straightforward. Concerning downstreams of $\alabellongind[{\tt addAfter}]{a,b}{\bot}{\ats_b}{}$ operations, we show that they are simulated by the corresponding specification operation $\alabelshort[{\tt addAfter}]{a,b}$ only when the timestamp $\ats_{\tt b}$ is strictly greater than all the timestamps stored in the replica state where it applies. This is sufficient because, by $\mathsf{ReplicaStates}$, every replica state is obtained by applying downstreams according to the linearization of their corresponding operations, and the linearization order is consistent with the timestamp order. Thus, let $({\tt N},{\tt Tomb})$ be a replica state such that $\ats_{\tt a} < \ats_{\tt b}$ for every $\ats_{\tt a}$ such that $({\tt c},\ats_{\tt a},{\tt a})\in {\tt N}$ for some ${\tt c}$. The effect of the downstream $\effector$ corresponding to $\alabellongind[{\tt addAfter}]{a,b}{\bot}{\ats_b}{}$ is to add ${\tt b}$ as a child of ${\tt a}$. Then, applying ${\tt traverse}$ on the new state will result in a sequence where ${\tt b}$ is placed just after ${\tt a}$ because it has the biggest timestamp among the children of ${\tt a}$ (and all the nodes in the tree ${\tt N}$). This corresponds exactly to the sequence obtained by applying the operation $\alabelshort[{\tt addAfter}]{a,b}$ in the context of the specification.

To prove that $\mathsf{\CRDTLinshort{}}$ is an inductive invariant, we use almost the same arguments as in the case of OR-Set. The two notable differences are that in this case, the specification doesn't admit any sequence of updates and also, that downstreams of ${\tt addAfter}$ operations are simulated by the corresponding specification operations only under a certain condition related to timestamps. Concerning the first point, the specification requires that any $\alabelshort[{\tt addAfter}]{a,b}$ or $\alabelshort[{\tt remove}]{a}$ operation is preceded by an operation adding ${\tt a}$. However, since $\alinord$ is consistent with the visibility relation, and the preconditions of the RGA $\alabelshort[{\tt addAfter}]{a,b}$ and $\alabelshort[{\tt remove}]{a}$ operations ensure that an operation $\alabelshort[{\tt addAfter}]{c,a}$, for some ${\tt c}$, is visible when applying them at the origin replica, it follows that the projection of $\alinord$ on updates is admitted by the specification. Second, we have to show that the side-condition added to the simulation of ${\tt addAfter}$ downstreams still guarantees that any sequence $\mathsf{dseq}$ of downstream applications consistent with the linearization order (considering only such sequences is possible because of the $\mathsf{ReplicaStates}$ invariant) can be simulated by the specification. This follows from the fact that the linearization order is consistent with the timestamps generated by operations, which implies that any ${\tt addAfter}$ downstream adding an element ${\tt b}$ with timestamp $\ats_{\tt b}$ is ordered in $\mathsf{dseq}$ after all ${\tt addAfter}$ downstreams adding elements with timestamps smaller than $\ats_{\tt b}$.

TODO STATE WHICH OTHER OBJECTS SUPPORT THE SAME KIND OF PROOF.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "draft"
%%% End:
